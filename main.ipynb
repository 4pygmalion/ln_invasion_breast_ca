{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model import build_model\n",
    "from load_data import get_patches_path, data_generate\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "INPUT_PATCH_FOLDER = \"data/train_imgs_patch\"\n",
    "PATCH_WIDTH = 128\n",
    "PATCH_SHAPE = (PATCH_WIDTH, PATCH_WIDTH, 3)\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_csv(\"data/train.csv\")\n",
    "bag_names = list(clinical_data[\"ID\"])\n",
    "labels = list(clinical_data[\"N_category\"])\n",
    "patch_bags = get_patches_path(INPUT_PATCH_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_bag_names,\n",
    "    val_bag_names,\n",
    "    train_y,\n",
    "    val_y,\n",
    "    train_bags,\n",
    "    val_bags,\n",
    ") = train_test_split(\n",
    "    bag_names[: len(patch_bags)], labels[: len(patch_bags)], patch_bags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "        generator=data_generate,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape([None, PATCH_WIDTH, PATCH_WIDTH, 3]),\n",
    "            tf.TensorShape([1, 1]),\n",
    "        ),\n",
    "        args=(train_bag_names, train_y, train_bags),\n",
    "    )\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=data_generate,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=(\n",
    "        tf.TensorShape([None, PATCH_WIDTH, PATCH_WIDTH, 3]),\n",
    "        tf.TensorShape([1, 1]),\n",
    "    ),\n",
    "    args=(val_bag_names, val_y, val_bags),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(PATCH_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"check_points\", exist_ok=True)\n",
    "model_name = (\n",
    "        \"check_points/\"\n",
    "        + \"acc({accuracy:.4f})\"\n",
    "        + \"epoch({epoch})\"\n",
    "        + \"val_loss({val_loss:.4f}).hd5\"\n",
    "    )\n",
    "\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_name,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,  # (=decay)\n",
    "    verbose=True,\n",
    ")\n",
    "callbacks = [check_point, early_stopping, reduce_lr]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.repeat(),\n",
    "    validation_data=val_dataset.repeat(),\n",
    "    callbacks=callbacks,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=int(len(train_bag_names) / BATCH_SIZE),\n",
    "    validation_steps=int(len(val_bag_names) / BATCH_SIZE),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('breast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5416d1d2d283e47e38bff8a971e953fd3db1dda75b1e0a455953dc514b6bf7e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
